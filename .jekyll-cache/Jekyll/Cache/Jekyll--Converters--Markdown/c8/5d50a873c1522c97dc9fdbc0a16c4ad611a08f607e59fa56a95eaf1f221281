I"d<h1 id="publications">Publications</h1>

<h2 id="recent-works">Recent Works</h2>

<p>(For a full list of publications, see <a href="#full-list-of-publications">below</a>)</p>

<div class="row">

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>CLUES: A Benchmark for Learning Classifiers using Natural Language Explanations</pubtit>
      <p><img src="/images/pubpic/clues.jpg" class="img-responsive" width="33%" style="float: left" /></p>
      <p>Supervised learning has traditionally focused on inductive learning by observing labeled examples of a task. In contrast, humans have the ability to learn new concepts from language. Here, we explore learning zero-shot classifiers for structured data purely from language from natural language explanations as supervision. For this, we introduce CLUES, a benchmark consisting of a range of classification tasks over structured data along with natural language supervision in the form of explanations.</p>
      <p>
    <a href="https://cs.unc.edu/~rrmenon">Rakesh R Menon*</a>, 
    <a href="https://sgdgp.github.io">Sayan Ghosh*</a>, and 
    <a href="https://ssriva.com">Shashank Srivastava</a>
  <br />
  </p>
      <p>Proceedings of Association for Computational Linguistics (ACL), 2022.<br /></p>
      <p>[<a href="https://aclanthology.org/2022.acl-long.451.pdf">pdf</a>]</p>
    </div>
  </div>

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>Improving and Simplifying Pattern Exploiting Training</pubtit>
      <p><img src="/images/pubpic/adapet.jpg" class="img-responsive" width="33%" style="float: left" /></p>
      <p>Pattern Exploiting Training (PET) is a recent approach that leverages patterns for few-shot learning. However, PET uses task-specific unlabeled data. In this paper, we focus on few shot learning without any unlabeled data and introduce ADAPET, which modifies PETâ€™s objective to provide denser supervision during fine-tuning. As a result, ADAPET outperforms PET on SuperGLUE without any task-specific unlabeled data.</p>
      <p>
    Derek Tam*, 
    <a href="https://cs.unc.edu/~rrmenon">Rakesh R Menon*</a>, 
    Mohit Bansal, 
    <a href="https://ssriva.com">Shashank Srivastava</a>, and 
    Colin Raffel
  <br />
  </p>
      <p>Proceedings of Empirical Methods in Natural Language Processing (EMNLP), 2021.<br /></p>
      <p>[<a href="https://arxiv.org/pdf/2103.11955.pdf">pdf</a>]</p>
    </div>
  </div>

</div>

<p> Â  </p>

<h2 id="full-list-of-publications">Full List of publications</h2>

<h3>2022</h3>
<ol reversed="" start="2">


<li>
<p>
<strong>CLUES: A Benchmark for Learning Classifiers using Natural Language Explanations</strong><br />
<a href="https://cs.unc.edu/~rrmenon">Rakesh R Menon*</a>, 
      
    <a href="https://sgdgp.github.io">Sayan Ghosh*</a>, 
       and 
    <a href="https://ssriva.com">Shashank Srivastava</a>
      
    
<br />
Proceedings of Association for Computational Linguistics (ACL), 2022.<br />

  
    [<a href="https://aclanthology.org/2022.acl-long.451.pdf">pdf</a>], 
  
    [<a href="https://arxiv.org/abs/2204.07142">arxiv</a>], 
  
    [<a href="https://www.github.com/rrmenon10/ExEnt">code</a>], 
  
    [<a href="https://clues-benchmark.github.io/">dataset</a>]
  

</p>
</li>







</ol>

<h3>2021</h3>
<ol reversed="" start="1">


<li>
<p>
<strong>Improving and Simplifying Pattern Exploiting Training</strong><br />
Derek Tam*, 
      
    <a href="https://cs.unc.edu/~rrmenon">Rakesh R Menon*</a>, 
      
    Mohit Bansal, 
      
    <a href="https://ssriva.com">Shashank Srivastava</a>, 
       and 
    Colin Raffel
      
    
<br />
Proceedings of Empirical Methods in Natural Language Processing (EMNLP), 2021.<br />

  
    [<a href="https://arxiv.org/pdf/2103.11955.pdf">pdf</a>], 
  
    [<a href="https://arxiv.org/abs/2103.11955">arxiv</a>], 
  
    [<a href="https://www.github.com/rrmenon10/ADAPET">code</a>]
  

</p>
</li>



</ol>

:ET